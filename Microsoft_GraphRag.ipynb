{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--microsoft-graphrag)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Microsoft GraphRAG: Enhancing Retrieval-Augmented Generation with Knowledge Graphs\n",
        "\n",
        " \n",
        "## Overview\n",
        "\n",
        " \n",
        "Microsoft GraphRAG is an advanced Retrieval-Augmented Generation (RAG) system that integrates knowledge graphs to improve the performance of large language models (LLMs). Developed by Microsoft Research, GraphRAG addresses limitations in traditional RAG approaches by using LLM-generated knowledge graphs to enhance document analysis and improve response quality.\n",
        "\n",
        "## Motivation\n",
        "\n",
        " \n",
        "Traditional RAG systems often struggle with complex queries that require synthesizing information from disparate sources. GraphRAG aims to:\n",
        "Connect related information across datasets.\n",
        "Enhance understanding of semantic concepts.\n",
        "Improve performance on global sensemaking tasks.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "Knowledge Graph Generation: Constructs graphs with entities as nodes and relationships as edges.\n",
        "Community Detection: Identifies clusters of related entities within the graph.\n",
        "Summarization: Generates summaries for each community to provide context for LLMs.\n",
        "Query Processing: Uses these summaries to enhance the LLM's ability to answer complex questions.\n",
        "## Method Details\n",
        "\n",
        "Indexing Stage\n",
        "\n",
        " \n",
        "Text Chunking: Splits source texts into manageable chunks.\n",
        "Element Extraction: Uses LLMs to identify entities and relationships.\n",
        "Graph Construction: Builds a graph from the extracted elements.\n",
        "Community Detection: Applies algorithms like Leiden to find communities.\n",
        "Community Summarization: Creates summaries for each community.\n",
        "\n",
        "Query Stage\n",
        "\n",
        " \n",
        "Local Answer Generation: Uses community summaries to generate preliminary answers.\n",
        "Global Answer Synthesis: Combines local answers to form a comprehensive response.\n",
        "\n",
        "\n",
        "## Benefits of GraphRAG\n",
        "GraphRAG is a powerful tool that addresses some of the key limitations of the baseline RAG model. Unlike the standard RAG model, GraphRAG excels at identifying connections between disparate pieces of information and drawing insights from them. This makes it an ideal choice for users who need to extract insights from large data collections or documents that are difficult to summarize. By leveraging its advanced graph-based architecture, GraphRAG is able to provide a holistic understanding of complex semantic concepts, making it an invaluable tool for anyone who needs to find information quickly and accurately. Whether you're a researcher, analyst, or just someone who needs to stay informed, GraphRAG can help you connect the dots and uncover new insights.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "Microsoft GraphRAG represents a significant step forward in retrieval-augmented generation, particularly for tasks requiring a global understanding of datasets. By incorporating knowledge graphs, it offers improved performance, making it ideal for complex information retrieval and analysis.\n",
        "\n",
        "For those experienced with basic RAG systems, GraphRAG offers an opportunity to explore more sophisticated solutions, although it may not be necessary for all use cases.\n",
        "Retrieval Augmented Generation (RAG) is often performed by chunking long texts, creating a text embedding for each chunk, and retrieving chunks for including in the LLM generation context based on a similarity search against the query. This approach works well in many scenarios, and at compelling speed and cost trade-offs, but doesn't always cope well in scenarios where a detailed understanding of the text is required.\n",
        "\n",
        "GraphRag ( [microsoft.github.io/graphrag](https://microsoft.github.io/graphrag/) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/Microsoft_GraphRag.svg\" alt=\"adaptive retrieval\" style=\"width:100%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To run this notebook you can use either OpenAI API key or Azure OpenAI key. \n",
        "Create a `.env` file and fill in the credentials for your OpenAI or Azure Open AI deployment. The following code loads these environment variables and sets up our AI client.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "AZURE_OPENAI_API_KEY=\"\"\n",
        "AZURE_OPENAI_ENDPOINT=\"\"\n",
        "GPT4O_MODEL_NAME=\"gpt-4o\"\n",
        "TEXT_EMBEDDING_3_LARGE_DEPLOYMENT_NAME=\"\"\n",
        "AZURE_OPENAI_API_VERSION=\"2024-06-01\"\n",
        "\n",
        "OPENAI_API_KEY=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting graphrag\n",
            "  Downloading graphrag-2.4.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting aiofiles<25.0.0,>=24.1.0 (from graphrag)\n",
            "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting azure-cosmos<5.0.0,>=4.9.0 (from graphrag)\n",
            "  Downloading azure_cosmos-4.9.0-py3-none-any.whl.metadata (80 kB)\n",
            "Collecting azure-identity<2.0.0,>=1.19.0 (from graphrag)\n",
            "  Downloading azure_identity-1.23.1-py3-none-any.whl.metadata (82 kB)\n",
            "Collecting azure-search-documents<12.0.0,>=11.5.2 (from graphrag)\n",
            "  Downloading azure_search_documents-11.5.3-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting azure-storage-blob<13.0.0,>=12.24.0 (from graphrag)\n",
            "  Downloading azure_storage_blob-12.26.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting devtools<0.13.0,>=0.12.2 (from graphrag)\n",
            "  Downloading devtools-0.12.2-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting environs<12.0.0,>=11.0.0 (from graphrag)\n",
            "  Downloading environs-11.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting fnllm<0.4.0,>=0.3.0 (from fnllm[azure,openai]<0.4.0,>=0.3.0->graphrag)\n",
            "  Downloading fnllm-0.3.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting future<2.0.0,>=1.0.0 (from graphrag)\n",
            "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting graspologic<4.0.0,>=3.4.1 (from graphrag)\n",
            "  Downloading graspologic-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting json-repair<0.31.0,>=0.30.3 (from graphrag)\n",
            "  Downloading json_repair-0.30.3-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting lancedb<0.18.0,>=0.17.0 (from graphrag)\n",
            "  Downloading lancedb-0.17.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: networkx<4.0.0,>=3.4.2 in ./venv/lib/python3.11/site-packages (from graphrag) (3.5)\n",
            "Requirement already satisfied: nltk==3.9.1 in ./venv/lib/python3.11/site-packages (from graphrag) (3.9.1)\n",
            "Collecting numpy<2.0.0,>=1.25.2 (from graphrag)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.0 in ./venv/lib/python3.11/site-packages (from graphrag) (1.99.1)\n",
            "Collecting pandas<3.0.0,>=2.2.3 (from graphrag)\n",
            "  Using cached pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (91 kB)\n",
            "Collecting pyarrow>=17.0.0 (from graphrag)\n",
            "  Using cached pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.3 in ./venv/lib/python3.11/site-packages (from graphrag) (2.11.7)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in ./venv/lib/python3.11/site-packages (from graphrag) (1.1.1)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in ./venv/lib/python3.11/site-packages (from graphrag) (6.0.2)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.8.4 in ./venv/lib/python3.11/site-packages (from graphrag) (3.8.7)\n",
            "Collecting textblob<0.19.0,>=0.18.0.post0 (from graphrag)\n",
            "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting tiktoken<0.10.0,>=0.9.0 (from graphrag)\n",
            "  Using cached tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.67.1 in ./venv/lib/python3.11/site-packages (from graphrag) (4.67.1)\n",
            "Requirement already satisfied: typer<0.17.0,>=0.16.0 in ./venv/lib/python3.11/site-packages (from graphrag) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in ./venv/lib/python3.11/site-packages (from graphrag) (4.14.1)\n",
            "Collecting umap-learn<0.6.0,>=0.5.6 (from graphrag)\n",
            "  Downloading umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: click in ./venv/lib/python3.11/site-packages (from nltk==3.9.1->graphrag) (8.2.1)\n",
            "Requirement already satisfied: joblib in ./venv/lib/python3.11/site-packages (from nltk==3.9.1->graphrag) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.11/site-packages (from nltk==3.9.1->graphrag) (2025.7.34)\n",
            "Collecting azure-core>=1.30.0 (from azure-cosmos<5.0.0,>=4.9.0->graphrag)\n",
            "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting cryptography>=2.5 (from azure-identity<2.0.0,>=1.19.0->graphrag)\n",
            "  Downloading cryptography-45.0.6-cp311-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
            "Collecting msal>=1.30.0 (from azure-identity<2.0.0,>=1.19.0->graphrag)\n",
            "  Downloading msal-1.33.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=1.2.0 (from azure-identity<2.0.0,>=1.19.0->graphrag)\n",
            "  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting azure-common>=1.1 (from azure-search-documents<12.0.0,>=11.5.2->graphrag)\n",
            "  Using cached azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting isodate>=0.6.0 (from azure-search-documents<12.0.0,>=11.5.2->graphrag)\n",
            "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting asttokens<3.0.0,>=2.0.0 (from devtools<0.13.0,>=0.12.2->graphrag)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting executing>=1.1.1 (from devtools<0.13.0,>=0.12.2->graphrag)\n",
            "  Using cached executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pygments>=2.15.0 in ./venv/lib/python3.11/site-packages (from devtools<0.13.0,>=0.12.2->graphrag) (2.19.1)\n",
            "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.11/site-packages (from asttokens<3.0.0,>=2.0.0->devtools<0.13.0,>=0.12.2->graphrag) (1.17.0)\n",
            "Requirement already satisfied: marshmallow>=3.13.0 in ./venv/lib/python3.11/site-packages (from environs<12.0.0,>=11.0.0->graphrag) (3.26.1)\n",
            "Collecting aiolimiter>=1.1.0 (from fnllm<0.4.0,>=0.3.0->fnllm[azure,openai]<0.4.0,>=0.3.0->graphrag)\n",
            "  Downloading aiolimiter-1.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.11/site-packages (from fnllm<0.4.0,>=0.3.0->fnllm[azure,openai]<0.4.0,>=0.3.0->graphrag) (0.28.1)\n",
            "Requirement already satisfied: tenacity>=8.5.0 in ./venv/lib/python3.11/site-packages (from fnllm<0.4.0,>=0.3.0->fnllm[azure,openai]<0.4.0,>=0.3.0->graphrag) (9.1.2)\n",
            "Collecting POT<0.10,>=0.9 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading POT-0.9.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (34 kB)\n",
            "Collecting anytree<3.0.0,>=2.12.1 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading anytree-2.13.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting beartype<0.19.0,>=0.18.5 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading beartype-0.18.5-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting gensim<5.0.0,>=4.3.2 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading gensim-4.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
            "Collecting graspologic-native<2.0.0,>=1.2.1 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading graspologic_native-1.2.5-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (2.6 kB)\n",
            "Collecting hyppo<0.5.0,>=0.4.0 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading hyppo-0.4.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.8.4 in ./venv/lib/python3.11/site-packages (from graspologic<4.0.0,>=3.4.1->graphrag) (3.10.5)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.4.2 in ./venv/lib/python3.11/site-packages (from graspologic<4.0.0,>=3.4.1->graphrag) (1.7.1)\n",
            "Collecting scipy==1.12.0 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading scipy-1.12.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (165 kB)\n",
            "Collecting seaborn<0.14.0,>=0.13.2 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting statsmodels<0.15.0,>=0.14.2 (from graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Using cached statsmodels-0.14.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in ./venv/lib/python3.11/site-packages (from gensim<5.0.0,>=4.3.2->graspologic<4.0.0,>=3.4.1->graphrag) (7.3.0.post1)\n",
            "Collecting numba>=0.46 (from hyppo<0.5.0,>=0.4.0->graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.8 kB)\n",
            "Collecting autograd>=1.3 (from hyppo<0.5.0,>=0.4.0->graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading autograd-1.8.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting deprecation (from lancedb<0.18.0,>=0.17.0->graphrag)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "INFO: pip is looking at multiple versions of lancedb to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting lancedb<0.18.0,>=0.17.0 (from graphrag)\n",
            "  Downloading lancedb-0.17.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (4.7 kB)\n",
            "Collecting pylance==0.20.0 (from lancedb<0.18.0,>=0.17.0->graphrag)\n",
            "  Downloading pylance-0.20.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: packaging in ./venv/lib/python3.11/site-packages (from lancedb<0.18.0,>=0.17.0->graphrag) (25.0)\n",
            "Collecting overrides>=0.7 (from lancedb<0.18.0,>=0.17.0->graphrag)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic<4.0.0,>=3.4.1->graphrag) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic<4.0.0,>=3.4.1->graphrag) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic<4.0.0,>=3.4.1->graphrag) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic<4.0.0,>=3.4.1->graphrag) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic<4.0.0,>=3.4.1->graphrag) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic<4.0.0,>=3.4.1->graphrag) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.11/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic<4.0.0,>=3.4.1->graphrag) (2.9.0.post0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.0->graphrag) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.0->graphrag) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.0->graphrag) (0.10.0)\n",
            "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.68.0->graphrag) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.0->graphrag) (3.10)\n",
            "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx>=0.27.0->fnllm<0.4.0,>=0.3.0->fnllm[azure,openai]<0.4.0,>=0.3.0->graphrag) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx>=0.27.0->fnllm<0.4.0,>=0.3.0->fnllm[azure,openai]<0.4.0,>=0.3.0->graphrag) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->fnllm<0.4.0,>=0.3.0->fnllm[azure,openai]<0.4.0,>=0.3.0->graphrag) (0.16.0)\n",
            "Collecting pytz>=2020.1 (from pandas<3.0.0,>=2.2.3->graphrag)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=2.2.3->graphrag)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.3->graphrag) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.3->graphrag) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.10.3->graphrag) (0.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.11/site-packages (from scikit-learn<2.0.0,>=1.4.2->graspologic<4.0.0,>=3.4.1->graphrag) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (2.32.4)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (3.1.6)\n",
            "Requirement already satisfied: setuptools in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (80.9.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.8.4->graphrag) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in ./venv/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.8.4->graphrag) (1.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.8.4->graphrag) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.8.4->graphrag) (2.5.0)\n",
            "Collecting patsy>=0.5.6 (from statsmodels<0.15.0,>=0.14.2->graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in ./venv/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.8.4->graphrag) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./venv/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.8.4->graphrag) (0.1.5)\n",
            "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy<4.0.0,>=3.8.4->graphrag)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy<4.0.0,>=3.8.4->graphrag)\n",
            "  Downloading blis-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in ./venv/lib/python3.11/site-packages (from typer<0.17.0,>=0.16.0->graphrag) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in ./venv/lib/python3.11/site-packages (from typer<0.17.0,>=0.16.0->graphrag) (14.1.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn<0.6.0,>=0.5.6->graphrag)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.8.4->graphrag) (0.21.1)\n",
            "Requirement already satisfied: wrapt in ./venv/lib/python3.11/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.2->graspologic<4.0.0,>=3.4.1->graphrag) (1.17.2)\n",
            "Collecting cffi>=1.14 (from cryptography>=2.5->azure-identity<2.0.0,>=1.19.0->graphrag)\n",
            "  Using cached cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
            "Collecting pycparser (from cffi>=1.14->cryptography>=2.5->azure-identity<2.0.0,>=1.19.0->graphrag)\n",
            "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in ./venv/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.8.4->graphrag) (1.2.1)\n",
            "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0.0,>=1.19.0->graphrag)\n",
            "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.46->hyppo<0.5.0,>=0.4.0->graspologic<4.0.0,>=3.4.1->graphrag)\n",
            "  Downloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<0.17.0,>=0.16.0->graphrag) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.17.0,>=0.16.0->graphrag) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->spacy<4.0.0,>=3.8.4->graphrag) (3.0.2)\n",
            "Downloading graphrag-2.4.0-py3-none-any.whl (369 kB)\n",
            "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading azure_cosmos-4.9.0-py3-none-any.whl (303 kB)\n",
            "Downloading azure_identity-1.23.1-py3-none-any.whl (186 kB)\n",
            "Downloading azure_search_documents-11.5.3-py3-none-any.whl (298 kB)\n",
            "Downloading azure_storage_blob-12.26.0-py3-none-any.whl (412 kB)\n",
            "Downloading devtools-0.12.2-py3-none-any.whl (19 kB)\n",
            "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading environs-11.2.1-py3-none-any.whl (12 kB)\n",
            "Downloading fnllm-0.3.1-py3-none-any.whl (78 kB)\n",
            "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
            "Downloading graspologic-3.4.1-py3-none-any.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp311-cp311-macosx_12_0_arm64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading anytree-2.13.0-py3-none-any.whl (45 kB)\n",
            "Downloading beartype-0.18.5-py3-none-any.whl (917 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp311-cp311-macosx_11_0_arm64.whl (24.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m611.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading graspologic_native-1.2.5-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (648 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.4/648.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading hyppo-0.4.0-py3-none-any.whl (146 kB)\n",
            "Downloading json_repair-0.30.3-py3-none-any.whl (18 kB)\n",
            "Downloading lancedb-0.17.0-cp39-abi3-macosx_11_0_arm64.whl (24.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.20.0-cp39-abi3-macosx_11_0_arm64.whl (29.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/29.3 MB\u001b[0m \u001b[31m529.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
            "Using cached pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
            "Downloading POT-0.9.5-cp311-cp311-macosx_11_0_arm64.whl (344 kB)\n",
            "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Using cached statsmodels-0.14.5-cp311-cp311-macosx_11_0_arm64.whl (9.7 MB)\n",
            "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl (774 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.2/774.2 kB\u001b[0m \u001b[31m695.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (1.0 MB)\n",
            "Downloading umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
            "Downloading aiolimiter-1.2.1-py3-none-any.whl (6.7 kB)\n",
            "Downloading autograd-1.8.0-py3-none-any.whl (51 kB)\n",
            "Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Downloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
            "Downloading cryptography-45.0.6-cp311-abi3-macosx_10_9_universal2.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl (178 kB)\n",
            "Using cached executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading msal-1.33.0-py3-none-any.whl (116 kB)\n",
            "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Using cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
            "Downloading numba-0.61.2-cp311-cp311-macosx_11_0_arm64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m800.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-macosx_11_0_arm64.whl (26.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.2/26.2 MB\u001b[0m \u001b[31m560.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hUsing cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
            "Using cached pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl (31.2 MB)\n",
            "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Installing collected packages: pytz, azure-common, tzdata, PyJWT, pycparser, pyarrow, overrides, numpy, llvmlite, json-repair, isodate, graspologic-native, future, executing, deprecation, beartype, asttokens, anytree, aiolimiter, aiofiles, tiktoken, textblob, scipy, pylance, patsy, pandas, numba, environs, devtools, cffi, blis, azure-core, autograd, statsmodels, POT, lancedb, gensim, fnllm, cryptography, azure-search-documents, azure-cosmos, thinc, seaborn, pynndescent, hyppo, azure-storage-blob, umap-learn, msal, msal-extensions, graspologic, azure-identity, graphrag\n",
            "\u001b[2K  Attempting uninstall: numpym━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/52\u001b[0m [pyarrow]\n",
            "\u001b[2K    Found existing installation: numpy 2.3.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/52\u001b[0m [pyarrow]\n",
            "\u001b[2K    Uninstalling numpy-2.3.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/52\u001b[0m [pyarrow]\n",
            "\u001b[2K      Successfully uninstalled numpy-2.3.2━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/52\u001b[0m [numpy]\n",
            "\u001b[2K  Attempting uninstall: executing90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/52\u001b[0m [future]e]\n",
            "\u001b[2K    Found existing installation: executing 0.8.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/52\u001b[0m [future]\n",
            "\u001b[2K    Uninstalling executing-0.8.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/52\u001b[0m [future]\n",
            "\u001b[2K      Successfully uninstalled executing-0.8.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/52\u001b[0m [future]\n",
            "\u001b[2K  Attempting uninstall: asttokens\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/52\u001b[0m [beartype]\n",
            "\u001b[2K    Found existing installation: asttokens 3.0.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/52\u001b[0m [beartype]\n",
            "\u001b[2K    Uninstalling asttokens-3.0.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/52\u001b[0m [beartype]\n",
            "\u001b[2K      Successfully uninstalled asttokens-3.0.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/52\u001b[0m [beartype]\n",
            "\u001b[2K  Attempting uninstall: tiktoken0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/52\u001b[0m [beartype]\n",
            "\u001b[2K    Found existing installation: tiktoken 0.10.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/52\u001b[0m [beartype]\n",
            "\u001b[2K    Uninstalling tiktoken-0.10.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/52\u001b[0m [beartype]\n",
            "\u001b[2K      Successfully uninstalled tiktoken-0.10.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/52\u001b[0m [beartype]\n",
            "\u001b[2K  Attempting uninstall: scipy90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/52\u001b[0m [tiktoken]\n",
            "\u001b[2K    Found existing installation: scipy 1.16.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/52\u001b[0m [tiktoken]\n",
            "\u001b[2K    Uninstalling scipy-1.16.1:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/52\u001b[0m [tiktoken]\n",
            "\u001b[2K      Successfully uninstalled scipy-1.16.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/52\u001b[0m [scipy]\n",
            "\u001b[2K  Attempting uninstall: blis\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/52\u001b[0m [numba]]]\n",
            "\u001b[2K    Found existing installation: blis 1.3.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/52\u001b[0m [numba]\n",
            "\u001b[2K    Uninstalling blis-1.3.0:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/52\u001b[0m [numba]\n",
            "\u001b[2K      Successfully uninstalled blis-1.3.00m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/52\u001b[0m [numba]\n",
            "\u001b[2K  Attempting uninstall: thinc━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m40/52\u001b[0m [azure-cosmos]documents]\n",
            "\u001b[2K    Found existing installation: thinc 8.3.6\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m40/52\u001b[0m [azure-cosmos]\n",
            "\u001b[2K    Uninstalling thinc-8.3.6:━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m41/52\u001b[0m [thinc]os]\n",
            "\u001b[2K      Successfully uninstalled thinc-8.3.61m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m41/52\u001b[0m [thinc]\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52/52\u001b[0m [graphrag]graphrag]azure-identity]lob]\n",
            "\u001b[1A\u001b[2KSuccessfully installed POT-0.9.5 PyJWT-2.10.1 aiofiles-24.1.0 aiolimiter-1.2.1 anytree-2.13.0 asttokens-2.4.1 autograd-1.8.0 azure-common-1.1.28 azure-core-1.35.0 azure-cosmos-4.9.0 azure-identity-1.23.1 azure-search-documents-11.5.3 azure-storage-blob-12.26.0 beartype-0.18.5 blis-1.2.1 cffi-1.17.1 cryptography-45.0.6 deprecation-2.1.0 devtools-0.12.2 environs-11.2.1 executing-2.2.0 fnllm-0.3.1 future-1.0.0 gensim-4.3.3 graphrag-2.4.0 graspologic-3.4.1 graspologic-native-1.2.5 hyppo-0.4.0 isodate-0.7.2 json-repair-0.30.3 lancedb-0.17.0 llvmlite-0.44.0 msal-1.33.0 msal-extensions-1.3.1 numba-0.61.2 numpy-1.26.4 overrides-7.7.0 pandas-2.3.1 patsy-1.0.1 pyarrow-21.0.0 pycparser-2.22 pylance-0.20.0 pynndescent-0.5.13 pytz-2025.2 scipy-1.12.0 seaborn-0.13.2 statsmodels-0.14.5 textblob-0.18.0.post0 thinc-8.3.4 tiktoken-0.9.0 tzdata-2025.2 umap-learn-0.5.9.post2\n"
          ]
        }
      ],
      "source": [
        "!pip install graphrag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Package Installation and Imports\n",
        "\n",
        "The cell below installs all necessary packages required to run this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting beautifulsoup4\n",
            "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: openai in ./venv/lib/python3.11/site-packages (1.99.1)\n",
            "Requirement already satisfied: python-dotenv in ./venv/lib/python3.11/site-packages (1.1.1)\n",
            "Requirement already satisfied: pyyaml in ./venv/lib/python3.11/site-packages (6.0.2)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
            "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in ./venv/lib/python3.11/site-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.11/site-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.11/site-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
            "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: soupsieve, beautifulsoup4\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [beautifulsoup4]\n",
            "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.4 soupsieve-2.7\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install beautifulsoup4 openai python-dotenv pyyaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Package Installation\n",
        "\n",
        "The cell below installs all necessary packages required to run this notebook. If you're running this notebook in a new environment, execute this cell first to ensure all dependencies are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in ./venv/lib/python3.11/site-packages (1.99.1)\n",
            "Requirement already satisfied: python-dotenv in ./venv/lib/python3.11/site-packages (1.1.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.11/site-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.11/site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.11/site-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in ./venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.11/site-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in ./venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "from openai import AzureOpenAI, OpenAI\n",
        "\n",
        "AZURE=True #Change to False to use OpenAI\n",
        "if AZURE:\n",
        "    AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "    AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    GPT4O_DEPLOYMENT_NAME = os.getenv(\"GPT4O_MODEL_NAME\")\n",
        "    TEXT_EMBEDDING_3_LARGE_NAME = os.getenv(\"TEXT_EMBEDDING_3_LARGE_DEPLOYMENT_NAME\")\n",
        "    AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
        "    oai = AzureOpenAI(azure_endpoint=AZURE_OPENAI_ENDPOINT, api_key=AZURE_OPENAI_API_KEY, api_version=AZURE_OPENAI_API_VERSION)\n",
        "else:\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    oai = OpenAI(api_key=OPENAI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll start by getting a text to work with. The Wikipedia article on Elon Musk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/Elon_Musk\"  # Replace with the URL of the web page you want to scrape\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "if not os.path.exists('data'):\n",
        "    os.makedirs('data')\n",
        "\n",
        "if not os.path.exists('data/elon.md'):\n",
        "    elon = soup.text.split('\\nSee also')[0]\n",
        "    with open('data/elon.md', 'w', encoding='utf-8') as f:\n",
        "        f.write(elon)\n",
        "else:\n",
        "    with open('data/elon.md', 'r') as f:\n",
        "        elon = f.read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GraphRag has a convenient set of CLI commands we can use. We'll start by configuring the system, then run the indexing operation. Indexing with GraphRag is a much lengthier process, and one that costs significantly more, since rather than just calculating embeddings, GraphRag makes many LLM calls to analyse the text, extract entities, and construct the graph. That's a one-time expense, though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "if not os.path.exists('data/graphrag'):\n",
        "    !python -m graphrag.index --init --root data/graphrag\n",
        "\n",
        "with open('data/graphrag/settings.yaml', 'r') as f:\n",
        "    settings_yaml = yaml.load(f, Loader=yaml.FullLoader)\n",
        "settings_yaml['llm']['model'] = \"gpt-4o\"\n",
        "settings_yaml['llm']['api_key'] = AZURE_OPENAI_API_KEY if AZURE else OPENAI_API_KEY\n",
        "settings_yaml['llm']['type'] = 'azure_openai_chat' if AZURE else 'openai_chat'\n",
        "settings_yaml['embeddings']['llm']['api_key'] = AZURE_OPENAI_API_KEY if AZURE else OPENAI_API_KEY\n",
        "settings_yaml['embeddings']['llm']['type'] = 'azure_openai_embedding' if AZURE else 'openai_embedding'\n",
        "settings_yaml['embeddings']['llm']['model'] = TEXT_EMBEDDING_3_LARGE_NAME if AZURE else 'text-embedding-3-large'\n",
        "if AZURE:\n",
        "    settings_yaml['llm']['api_version'] = AZURE_OPENAI_API_VERSION\n",
        "    settings_yaml['llm']['deployment_name'] = GPT4O_DEPLOYMENT_NAME\n",
        "    settings_yaml['llm']['api_base'] = AZURE_OPENAI_ENDPOINT\n",
        "    settings_yaml['embeddings']['llm']['api_version'] = AZURE_OPENAI_API_VERSION\n",
        "    settings_yaml['embeddings']['llm']['deployment_name'] = TEXT_EMBEDDING_3_LARGE_NAME\n",
        "    settings_yaml['embeddings']['llm']['api_base'] = AZURE_OPENAI_ENDPOINT\n",
        "\n",
        "with open('data/graphrag/settings.yaml', 'w') as f:\n",
        "    yaml.dump(settings_yaml, f)\n",
        "\n",
        "if not os.path.exists('data/graphrag/input'):\n",
        "    os.makedirs('data/graphrag/input')\n",
        "    !cp data/elon.md data/graphrag/input/elon.txt\n",
        "    !python -m graphrag.index --root ./data/graphrag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should get an output:\n",
        "🚀 \u001bAll workflows completed successfully.\u001b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To query GraphRag we'll use its CLI again, making sure to configure it with a context length equivalent to what we use in our embeddings search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import re\n",
        "DEFAULT_RESPONSE_TYPE = 'Summarize and explain in 1-2 paragraphs with bullet points using at most 300 tokens'\n",
        "DEFAULT_MAX_CONTEXT_TOKENS = 10000\n",
        "\n",
        "def remove_data(text):\n",
        "    return re.sub(r'\\[Data:.*?\\]', '', text).strip()\n",
        "\n",
        "\n",
        "def ask_graph(query,method):\n",
        "    env = os.environ.copy() | {\n",
        "      'GRAPHRAG_GLOBAL_SEARCH_MAX_TOKENS': str(DEFAULT_MAX_CONTEXT_TOKENS),\n",
        "    }\n",
        "    command = [\n",
        "      'python', '-m', 'graphrag.query',\n",
        "      '--root', './data/graphrag',\n",
        "      '--method', method,\n",
        "      '--response_type', DEFAULT_RESPONSE_TYPE,\n",
        "      query,\n",
        "    ]\n",
        "    output = subprocess.check_output(command, universal_newlines=True, env=env, stderr=subprocess.DEVNULL)\n",
        "    return remove_data(output.split('Search Response: ')[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GrpahRag offers 2 types of search:\n",
        "1. Global Search for reasoning about holistic questions about the corpus by leveraging the community summaries.\n",
        "2. Local Search for reasoning about specific entities by fanning-out to their neighbors and associated concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the local search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Elon Musk has founded several companies and subsidiaries across various industries. Here's a summary:\n",
              "\n",
              "- **SpaceX**: Founded in 2002, SpaceX is a private aerospace manufacturer and space transportation company. Musk serves as the CEO and chief engineer .\n",
              "\n",
              "- **Tesla, Inc.**: Although not originally founded by Musk, he became an early investor and later the CEO and product architect, significantly shaping its direction .\n",
              "\n",
              "- **Neuralink**: Co-founded by Musk, this company focuses on developing brain-machine interfaces to enhance human-computer interaction .\n",
              "\n",
              "- **The Boring Company**: Founded by Musk, it specializes in tunnel construction and innovative transportation solutions .\n",
              "\n",
              "- **X.com/PayPal**: Musk co-founded X.com, which later became PayPal after merging with Confinity .\n",
              "\n",
              "- **Zip2**: Co-founded with his brother Kimbal, this was Musk's first venture, later acquired by Compaq .\n",
              "\n",
              "- **SolarCity**: Co-created by Musk, it was later acquired by Tesla and rebranded as Tesla Energy .\n",
              "\n",
              "- **xAI**: Founded in 2023, this company focuses on artificial intelligence research .\n",
              "\n",
              "- **OpenAI**: Co-founded by Musk, this nonprofit organization is dedicated to AI research .\n",
              "\n",
              "In total, Musk has founded or co-founded at least nine companies and subsidiaries."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "local_query=\"What and how many companies and subsidieries founded by Elon Musk\"\n",
        "local_result = ask_graph(local_query,'local')\n",
        "\n",
        "Markdown(local_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Elon Musk has achieved significant accomplishments across various industries, demonstrating his influence and innovation:\n",
              "\n",
              "- **Space Exploration**: Founder, CEO, and chief engineer of SpaceX, Musk has propelled the company to the forefront of space exploration and satellite deployment, establishing it as a leading spaceflight services provider .\n",
              "\n",
              "- **Automotive Industry**: As CEO of Tesla, Musk has driven the company to the forefront of electric vehicles and sustainable energy, significantly impacting the automotive industry with innovations in electric cars and energy solutions .\n",
              "\n",
              "- **Online Payments**: Co-founded X.com, which evolved into PayPal, revolutionizing online transactions and becoming a major player in the online payment industry .\n",
              "\n",
              "- **Neural Technology**: Co-founded Neuralink, focusing on advancing brain-machine interface technology to enhance the connection between the human brain and computers .\n",
              "\n",
              "- **Infrastructure**: Founded The Boring Company, specializing in tunnel construction to reduce traffic congestion through innovative underground transportation systems ."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "global_query=\"What are the major accomplishments of Elon Musk?\"\n",
        "global_result = ask_graph(global_query,'global')\n",
        "\n",
        "Markdown(global_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--microsoft-graphrag)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
